# -*- coding: utf-8 -*-
"""Copy of California House Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ijLSA2-aMJDwfxrk6b52h7zxXjX4axca

# California House Price Prediction Project

In this project I developed an end to end machine learning project using linear regression.

Importing the required libraries for the project.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd

import plotly.express as px
import plotly.graph_objects as go
import plotly.io as pio
pio.templates

import seaborn as sns 
import matplotlib.pyplot as plt
# %matplotlib inline

"""Loading the California Housing dataset from the scikit-learn library"""

from sklearn.datasets import fetch_california_housing
housing = fetch_california_housing()
x = housing.data
y = housing.target

data = pd.DataFrame(x, columns=housing.feature_names) # Using pandas to turn the dataset to a dataframe 
data["SalePrice"] = y 
data.head() # Getting the first 5 rows of the dataframe

"""Dataset Description"""

print(housing.DESCR)

print(data.shape) # Getting the number of rows and columns in the dataset

"""This tells us that we have 20640 rows and 9 columns in the dataset."""

data.info() # Gives us the datatypes and checks if there are missing values in the columns

data.describe() # Gives us the count,mean,standard deviation etc of the dataset

"""## Exploratory Data Analysis of the Dataset"""

data.isnull().sum() # Gives the sum of null values in the dataset columns. In this case there are none

sns.pairplot(data, height=2.5)
plt.tight_layout()

sns.distplot(data['SalePrice']); # Getting the distribution plot

print("Skewness: %f" % data['SalePrice'].skew())
print("Kurtosis: %f" % data['SalePrice'].kurt())

# Plotting HouseAge against SalesPrice
fig, ax = plt.subplots()
ax.scatter(x = data['HouseAge'], y = data['SalePrice'])
plt.ylabel('SalePrice', fontsize=13)
plt.xlabel('HouseAge', fontsize=13)
plt.show()

# Plotting AveRooms against SalesPrice
fig, ax = plt.subplots()
ax.scatter(x = data['AveRooms'], y = data['SalePrice'])
plt.ylabel('SalePrice', fontsize=13)
plt.xlabel('AveRooms', fontsize=13)
plt.show()

# Plotting AveBedrms against SalesPrice
fig, ax = plt.subplots()
ax.scatter(x = data['AveBedrms'], y = data['SalePrice'])
plt.ylabel('SalePrice', fontsize=13)
plt.xlabel('AveBedrms', fontsize=13)
plt.show()

from scipy import stats
from scipy.stats import norm, skew # For statistics Calculations

sns.distplot(data['SalePrice'], fit=norm);

(mu, sigma) = norm.fit(data['SalePrice'])
print('\n mu={:.2f} and sigma = {:.2f}\n'.format(mu, sigma))

plt.legend(['Normal dist. ($\mu=$ {:.2f} and $\sigma=$ {:.2f} )'.format(mu, sigma)],
            loc='best')
plt.ylabel('Frequency')
plt.title('SalePrice Distribution')

# Get also the QQ-plot
fig = plt.figure()
res=stats.probplot(data['SalePrice'], plot=plt)
plt.show

data['SalePrice']=np.log1p(data['SalePrice'])

sns.distplot(data['SalePrice'], fit=norm);

(mu, sigma) = norm.fit(data['SalePrice'])
print('\n mu={:.2f} and sigma = {:.2f}\n'.format(mu, sigma))

plt.legend(['Normal dist. ($\mu=$ {:.2f} and $\sigma=$ {:.2f} )'.format(mu, sigma)],
            loc='best')
plt.ylabel('Frequency')
plt.title('SalePrice Distribution')

fig = plt.figure()
res=stats.probplot(data['SalePrice'], plot=plt)
plt.show

"""## Data Correlation"""

plt.figure(figsize=(10,10))
cor = data.corr()
sns.heatmap(cor, annot=True, cmap=plt.cm.PuBu)
plt.show()

cor_target = abs(cor['SalePrice']) # absolute value of correlation

relevant_features = cor_target[cor_target>0.2] # highly correlated features

names = [index for index, value in relevant_features.iteritems()] # getting the names of the features

names.remove('SalePrice') # removing the target feature

print(names) # printing the features
print(len(names))

"""## Model Building"""

# Dividing the data into training and test set
from sklearn.model_selection import train_test_split

x = data.drop('SalePrice', axis=1)
y = data['SalePrice']
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)

# Gives the number of rows and columns for The X test, training set and Y test, training set
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

# Importing Linear Regression model from sklearn library
from sklearn.linear_model import LinearRegression

lr = LinearRegression() # Instantiating the Linear Regression Object
lr.fit(x_train, y_train) # Fitting the model
lr.score(x, y)

# Getting the predictions
predictions = lr.predict(x_test)

print('Actual value of the house:- $', y_test[0]*100000) # Present Value of the House in dollars
print("Model Predicted Value:-  $", predictions[0]*100000) # Predicted value of the House in dollars

# To check the accuracy using Mean Squared Error and Root Mean Squared Error and Getting the R-Squared Value of Predictions.

from sklearn.metrics import mean_squared_error, r2_score

mse = mean_squared_error(y_test, predictions)
rmse=np.sqrt(mse)
print('Mean Squared Error= ', mse)
print('Root Mean Squared Error= ',rmse)

Rsquared=r2_score(y_test, predictions)
print('R^2 Value= ', Rsquared*100,'%')